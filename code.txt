Assignment 1 

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

data = pd.read_csv("..\\Downloads\\iris.csv")

print(data)
data.head()
a = data.sample(10)
print(a)

print("max value sepal length ", data['sepal_length'].max())

data.fillna(0, inplace=True)
print("no null value sepal width", data['sepal_length'])
print("***********")
print(data.describe())
specific_data = data[["sepal_length", "sepal_length"]]
print("specified data", specific_data)
print("statistic calculation")
sum_data = data["sepal_length"].sum()
mean_data = data["sepal_length"].mean()
median_data = data["sepal_length"].median()

print("Sum:", sum_data, "\nmean:", mean_data, "\nmedian :", median_data)

data.describe()
data.info()
plt.figure(figsize=(151, 5))
x = data["sepal_length"]

plt.hist(x, bins=20, color="green")
plt.title("Sepal Length in cm")
plt.xlabel("sepal_length")
plt.ylabel("Count")
plt.show()


Assignment 2

import pandas as pd
import matplotlib.pyplot as plt

# assigning the data
data = {'Name': ['Adi', 'Deeksha', 'Jincy', 'Keerthi', 'Harish', 'Anu', 'Ram'],
        'Age': [17, 17, 18, 17, 18, 17, 17],
        'Gender': ['M', 'F', 'F', 'F', 'M', 'F', 'M'],
        'Marks': [90, 76, 'NAN', 74, 65, 'NAN', 71]}
# converting into the dataframes
df = pd.DataFrame(data)
# displaying the data
print(df)
# replacing the missing values
df = df.replace(to_replace="NAN", value=30)
# displaying the data
print(df)
print("RESHAPING THE DATA")
# Categorize the gender
df['Gender'] = df['Gender'].map({'M': 0, 'F': 1, }).astype(float)
# displaying the data
print(df)
# filter top scoring students
print("FILTERING THE DATA")
df = df[df['Marks'] >= 75]
# remove age row
df = df.drop(['Age'], axis=1)
# displaying the data
print("filter", df)
print("outlier with skewness")
print(df['Marks'].skew())
print(df['Marks'].describe())
print("GRAPTH")
plt.boxplot(df["Marks"])
plt.show()



Assignment 3

import statistics
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

data = pd.read_csv("C:\\Users\\Bhavika\\Downloads\\emp.csv")
data2 = np.array([7, 5, 4, 9, 12, 45])
print("Sum: ", data["EmployeeNumber"].sum())
print("Mean: ", data["EmployeeNumber"].mean())
print("Maximum: ", data["EmployeeNumber"].max())
print("Minimum: ", data["EmployeeNumber"].min())
print("Standard deviation: ", statistics.stdev(data["EmployeeNumber"]))

print("Standard Deviation of the sample is % s " % (statistics.stdev(data2)))
print("Mean of the sample is % s " % (statistics.mean(data2)))
0



Assignment 4

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline

data = pd.read_csv("HousingData.csv")
print(data.head())

print(data.tail())
print("The shape of data : ", data.shape)

data.isnull().sum()
data.fillna(0, inplace=True)
data.isnull().sum()

X = data.iloc[:,0:13]
y = data.iloc[:,-1]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())
model.fit(X_train, y_train)

print(model.score(X_test, y_test)*100)




Assignment 5 

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_recall_fscore_support
from sklearn.preprocessing import MinMaxScaler

df = pd.read_csv('Social_Network_Ads.csv')
print(df.shape)
print(df.head())

df.drop(['User ID'], axis=1, inplace=True)
print(df.head())

print(df.isnull().sum())

scaler = MinMaxScaler()
X = df[['Age', 'EstimatedSalary']]
X_scaled = scaler.fit_transform(X)
Y = df['Purchased']
print(X.head())

X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)
print("Training and testing split was successful.")

basemodel = LogisticRegression()
basemodel.fit(X_train, y_train)
print("Training accuracy:", basemodel.score(X_train, y_train) * 100)

y_predict = basemodel.predict(X_test)
print("Testing accuracy:", basemodel.score(X_test, y_test) * 100)

Acc = accuracy_score(y_test, y_predict)
print(Acc)

cm = confusion_matrix(y_test, y_predict)
print(cm)

prf = precision_recall_fscore_support(y_test, y_predict)
print('precision:', prf[0])
print('Recall:', prf[1])
print('fscore:', prf[2])
print('support:', prf[3])


Assignment 6

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix

data = pd.read_csv("C:\\Users\\Bhavika\\Downloads\\IRIS (2).csv")
print(data.head())
# splitting data in independent and dependent variable
X = data.iloc[:, :4].values
Y = data['species'].values

# splitting the dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=82)

# feature scaling to bring the variable in a single scale
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)
print("\n", X_train)

# Fitting Naive Bayes Classification to the training set with linear kernel
nvclassifier = GaussianNB()
nvclassifier.fit(X_train, y_train)

# Predicting the Test set results
y_pred = nvclassifier.predict(X_test)
print("\n", y_pred)

# Let's see the actual and predicted value side by side
y_compare = np.vstack((y_test, y_pred)).T

# printing the top 5 values
print("\n", y_compare[:5, :])

# Making confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("\n", cm)
TP = cm[0, 0]
TN = cm[1, 1] + cm[1, 2] + cm[2, 1] + cm[2, 2]
FP = cm[1, 0] + cm[2, 0]
FN = cm[0, 1] + cm[0, 2]
# printing confusion matrix, TP, FP, TN, FN
print("Confusion Matrix\n\n", cm)
print("\n True Positives (TP) = ", TP)
print("\n True Negatives (TN) = ", TN)
print("\n False Positives (FP) = ", FP)
print("\n False Negatives (FN) = ", FN)

print(classification_report(y_test, y_pred))
# finding accuracy
accuracy = (TP + TN) / float(TP + TN + FP + FN)
print("\n Accuracy = ", accuracy)

# finding error rate
error_rate = 1 - accuracy
print("\n Error Rate = ", error_rate)

# finding recall
recall = TP / float(TP + FN)
print("\n Recall = ", recall)

# finding precision score
precision = TP / float(TP + FP)
print("\n Precision = ", precision)



Assignment 7

import nltk

nltk.download('punkt')
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')
nltk.download('stopwords')
from nltk import sent_tokenize
from nltk import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk.stem.snowball import SnowballStemmer
from nltk.stem import LancasterStemmer
from nltk.stem import WordNetLemmatizer

lemma = WordNetLemmatizer()

text = 'Real madrid is set to win the UCL for the season . Benzema might win Balon dor . Salah might be the runner up'
tokens_sent = nltk.sent_tokenize(text)
print(tokens_sent)
tokens_words = nltk.word_tokenize(text)
print(tokens_words)

stem = []
for i in tokens_words:
    ps = PorterStemmer()
    stem_word = ps.stem(i)
    stem.append(stem_word)
print(stem)

print("\nLemmatization")

lem = WordNetLemmatizer()
lemma_output = ' '.join([lem.lemmatize(w) for w in stem])
print(lemma_output)
leme = []
for i in stem:
    lem_word = lem.lemmatize(i)
    leme.append(lem_word)
print(leme)

print("\nParts of Speech")
print("Parts of Speech: ",nltk.pos_tag(leme))

print("\nStopword")
sw_nltk = stopwords.words('english')
print(sw_nltk)
print(" ")
words = [word for word in text.split() if word.lower() not in sw_nltk]
new_text = " ".join(words)
print(new_text)


Assignment 8

# seaborn All operation

import seaborn as sns
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv("C:\\Users\\Bhavika\\Downloads\\train.csv", delimiter=',', quotechar='"')
print(df)

# Distribution plot
sns.displot(x=df['Age'])
sns.displot(x=df['Survived'], bins=5)
sns.displot(x=df['Sex'])
plt.show()

plt.hist(x=df['Age'], bins=5, histtype='step', align='right', orientation='vertical')
plt.title("Age")
plt.show()

plt.hist(x=df['Survived'], bins=5, histtype='step', align='right', orientation='horizontal')
plt.title("Survived")
plt.show()

plt.hist(x=df['Sex'], bins=5, histtype='stepfilled', align='left', color='blue')
plt.title("Sex")
plt.show()

print("joint plot")
sns.jointplot(x=df['Age'], y=df['Survived'], kind='scatter')
sns.jointplot(x=df['Survived'], y=df['Age'], kind='hex')
plt.show()

print("pair plot")
sns.rugplot(x=df['Fare'])
plt.show()

print("Bar plot")
sns.barplot(x=df['Survived'], y=df['Age'])
plt.show()
sns.barplot(x=df['Survived'], y=df['Age'], orient='h')
plt.show()

print("Count plot")
sns.countplot(df['Age'])
sns.set_theme(style='darkgrid')
plt.show()

print("Box plot")
sns.boxplot(y=df['Age'], x=df['Survived'])
plt.show()

print("violin plot")
sns.violinplot(y=df['Age'], x=df['Survived'], data=df, hue="Survived", orientation='right')
plt.show()

print("strip plot")
sns.stripplot(x=df['Age'], y=df['Sex'], data=df, jitter=True)
plt.show()

# In[43]:
print("swarm-plot")
sns.swarmplot(x=df['Sex'], y=df['Age'])
plt.show()

# In[45]:
print("heat map")
df["Age"] = df["Age"].fillna(df["Age"].mean())
df["Cabin"] = df["Cabin"].fillna(df["Cabin"].mode()[0])
df["Embarked"] = df["Embarked"].fillna(df["Embarked"].mode()[0])
df["Sex"] = [1 if i == "male" else 0 for i in df["Sex"]]
df["Embarked"] = [0 if i == "S" else i for i in df["Embarked"]]
df["Embarked"] = [1 if i == "C" else i for i in df["Embarked"]]
df["Embarked"] = [2 if i == "Q" else i for i in df["Embarked"]]
cols = ["Survived", "Pclass", "Sex", "Age", "SibSp", "Parch", "Fare", "Embarked"]
train_corr = df[cols].corr()
print(train_corr)
sns.heatmap(train_corr)
plt.show()

# In[ ]:
array_2d = np.linspace(1, 5, 12).reshape(4, 3)
print(array_2d)

# Seaborn heat map using numpy 2d array
# In[47]:
sns.heatmap(array_2d)
plt.show()



Assigment 9

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

data = pd.read_csv("train.csv")
sns.boxplot(x=data['Sex'], y=data["Age"])
sns.boxplot(x=data['Sex'], y=data["Age"], data=data["Survived"])
plt.show()



Assignment 10

import matplotlib.pyplot as plt
import pandas as pd

path = "C:\\Users\\Bhavika\\Downloads\\iris.csv"

df = pd.read_csv(path, header=None)

headers = ["Sepal-length", "Sepal-width", "Petal-length", "Petal-width", "Species"]
df.columns = headers

print(df.head())
print(df.tail())
print(df.info())
print(df.shape)
print(df.dtypes)
print(df.describe())

# df.hist()
# plt.show()

# df.boxplot()
# plt.show()

plt.scatter(df["Sepal-length"], df["Sepal-width"])
plt.xlabel('Sepal Length')
plt.ylabel('Sepal Width')
plt.show()

plt.scatter(df["Sepal-length"], df["Petal-length"])
plt.xlabel('Sepal Length')
plt.ylabel('Petal Width')
plt.show()

plt.scatter(df["Sepal-length"], df["Petal-width"])
plt.xlabel('Sepal Length')
plt.xlabel('Petal Width')
plt.show()

plt.scatter(df["Sepal-width"], df["Sepal-length"])
plt.xlabel('Sepal Width')
plt.ylabel('Sepal Length')
plt.show()

plt.scatter(df["Sepal-width"], df["Petal-length"])
plt.xlabel('Sepal Width')
plt.ylabel('Petal Length')
plt.show()

plt.scatter(df["Sepal-width"], df["Petal-width"])
plt.xlabel('Sepal Width')
plt.ylabel('Petal Width')
plt.show()

plt.scatter(df["Petal-length"], df["Sepal-length"])
plt.xlabel('Petal Length')
plt.ylabel('Sepal Length')
plt.show()

plt.scatter(df["Petal-length"], df["Sepal-width"])
plt.xlabel('Petal Length')
plt.ylabel('Sepal Width')
plt.show()

plt.scatter(df["Petal-length"], df["Petal-width"])
plt.xlabel('Petal Length')
plt.ylabel('Petal Width')
plt.show()

plt.scatter(df["Petal-width"], df["Sepal-length"])
plt.xlabel('Petal Width')
plt.xlabel('Sepal Length')
plt.show()

plt.scatter(df["Petal-width"], df["Sepal-width"])
plt.xlabel('Petal Width')
plt.xlabel('Sepal Width')
plt.show()

plt.scatter(df["Petal-width"], df["Petal-length"])
plt.xlabel('Petal Width')
plt.ylabel('Petal Length')
plt.show()
